<meta charset="utf-8">
<html>

<head>
  <title>Publications</title>
  <link href="css/bib_eriks.css" rel="stylesheet" type="text/css">
  <script src="bib.js"></script>
</head>

<body>


  <div class='block'>
    
    <h2>2024</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Squeezing Lemons with Hammers: An Evaluation of AutoML and Tabular Deep Learning for Data-Scarce Classification Applications.</span>
            <br />
            <span class=bibauthor>Knauer, Ricardo and Rodner, Erik.</span>
            <br />
            <span class=bibvenue>ICLR 2024 Workshop on Practical ML for Low Resource Settings.</span>
            
            <span class=bibyear>2024.</span>
            
            
            
            
            <a href="/bib/knauer2024squeezing"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2023</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              An Intelligent Camera Tracking System for Live Stage Performances.</span>
            <br />
            <span class=bibauthor>Borchers-Tigasson, Steffen and Rodner, Erik.</span>
            <br />
            <span class=bibvenue>Proceedings. 33. Workshop Computational Intelligence.</span>
            
            <span class=bibpages>143-154.</span>
            
            <span class=bibyear>2023.</span>
            
            
            
            
            <a href="/bib/tigasson2024ict"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="https://publikationen.bibliothek.kit.edu/1000162754"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Cost-Sensitive Best Subset Selection for Logistic Regression: A Mixed-Integer Conic Optimization Perspective.</span>
            <br />
            <span class=bibauthor>Knauer, Ricardo and Rodner, Erik.</span>
            <br />
            <span class=bibvenue>Proceedings of the German Conference on Artificial Intelligence (Künstliche Intelligenz).</span>
            
            <span class=bibpages>114-129.</span>
            
            <span class=bibyear>2023.</span>
            
            
            
            
            <a href="/bib/knauer2023cost"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              CAD Models to Real-World Images: A Practical Approach to Unsupervised Domain Adaptation in Industrial Object Classification.</span>
            <br />
            <span class=bibauthor>Ritter, Dennis and Hemberger, Mike and Hönig, Marc and Stopp, Volker and Rodner, Erik and Hildebrand, Kristian.</span>
            <br />
            <span class=bibvenue>European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD), Workshop Adapting to Change: Reliable Learning Across Domains.</span>
            
            <span class=bibyear>2023.</span>
            
            
            
            
            <a href="/bib/ritter2023cad"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="https://arxiv.org/abs/2310.04757"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Foundations for applied artificial intelligence: enabling and supporting AI teaching and research.</span>
            <br />
            <span class=bibauthor>Knauer, Ricardo and Wallsberger, Raphael and Grimm, Marvin and Bookhahn, Marian and Neumann, Frank and Matzka, Stephan and Rodner, Erik.</span>
            <br />
            <span class=bibvenue>.</span>
            
            <span class=bibpages>353-356.</span>
            
            <span class=bibyear>2023.</span>
            
            
            
            
            <a href="/bib/knauer2023foundations"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Blind Video Stabilization Quality Assessment based on convolutional LSTM.</span>
            <br />
            <span class=bibauthor>Yagoubi, Mohamed Riad and Amirshahi, Seyed Ali and Le Moan, Steven and Beghdadi, Azeddine and Rodner, Erik.</span>
            <br />
            <span class=bibvenue>2023 11th European Workshop on Visual Information Processing (EUVIP).</span>
            
            <span class=bibpages>1-6.</span>
            
            <span class=bibyear>2023.</span>
            
            
            
            
            <a href="/bib/yagoubi2023blind"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Decoupled Semantic Prototypes enable learning from diverse annotation types for semi-weakly segmentation in expert-driven domains.</span>
            <br />
            <span class=bibauthor>Reiß, Simon and Seibold, Constantin and Freytag, Alexander and Rodner, Erik and Stiefelhagen, Rainer.</span>
            <br />
            <span class=bibvenue>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.</span>
            
            <span class=bibpages>15495-15506.</span>
            
            <span class=bibyear>2023.</span>
            
            
            
            
            <a href="/bib/reiss2023decoupled"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Reiss_Decoupled_Semantic_Prototypes_Enable_Learning_From_Diverse_Annotation_Types_for_CVPR_2023_paper.html"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2022</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              OpenPredict - An Open Research Dataset and Evaluation Protocol for Fine-grained Predictive Testing.</span>
            <br />
            <span class=bibauthor>David Brodmann and Erik Rodner.</span>
            <br />
            <span class=bibvenue>.</span>
            
            <span class=bibyear>2022.</span>
            
            
            
            
            <a href="/bib/brodmann2022"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Graph-constrained contrastive regularization for semi-weakly volumetric segmentation.</span>
            <br />
            <span class=bibauthor>Reiß, Simon and Seibold, Constantin and Freytag, Alexander and Rodner, Erik and Stiefelhagen, Rainer.</span>
            <br />
            <span class=bibvenue>Proceedings of the European Conference on Computer Vision (ECCV).</span>
            
            <span class=bibpages>401-419.</span>
            
            <span class=bibyear>2022.</span>
            
            
            
            
            <a href="/bib/reiss2022graph"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136810396.pdf"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Evaluating Zero-Cost Active Learning for Object Detection.</span>
            <br />
            <span class=bibauthor>Probst, Dominik and Raza, Hasnain and Rodner, Erik.</span>
            <br />
            <span class=bibvenue>International Conference on Software Engineering and Formal Methods.</span>
            
            <span class=bibpages>38-47.</span>
            
            <span class=bibyear>2022.</span>
            
            
            
            
            <a href="/bib/probst2022evaluating"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2021</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Every annotation counts: Multi-label deep supervision for medical image segmentation.</span>
            <br />
            <span class=bibauthor>Reiß, Simon and Seibold, Constantin and Freytag, Alexander and Rodner, Erik and Stiefelhagen, Rainer.</span>
            <br />
            <span class=bibvenue>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR).</span>
            
            <span class=bibpages>9532-9542.</span>
            
            <span class=bibyear>2021.</span>
            
            
            
            
            <a href="/bib/reiss2021every"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Reiss_Every_Annotation_Counts_Multi-Label_Deep_Supervision_for_Medical_Image_Segmentation_CVPR_2021_paper.pdf"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2020</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Simon19_Implicit.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Simon19_Implicit.pdf">The whole is more than its parts? From explicit to implicit pose normalization</a>.</span>
            <br />
            <span class=bibauthor>Marcel Simon and Erik Rodner and Trevor Darell and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>IEEE Transactions on Pattern Analysis and Machine Intelligence.</span>
            
            
            <span class=bibpages>42(3):</span>
            
            
            <span class=bibpages>749-763.</span>
            
            <span class=bibyear>2020.</span>
            
            
            
            
            <a href="/bib/Simon19_Implicit"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Simon19_Implicit.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Simon19_Implicit');">more ...</span>
            <div class="bibabstract" id="Simon19_Implicit">
              <br />
              <div class='vspace'></div>
              Abstract: Fine-grained classification describes the automated recognition of visually similar object categories like birds species. Previous works were usually based on explicit pose normalization, i.e., the detection and description of object parts. However, recent models based on a final global average or bilinear pooling have achieved a comparable accuracy without this concept. In this paper, we analyze the advantages of these approaches over generic CNNs and explicit pose normalization approaches. We also show how they can achieve an implicit normalization of the object pose. A novel visualization technique called activation flow is introduced to investigate limitations in pose handling in traditional CNNs like AlexNet and VGG. Afterward, we present and compare the explicit pose normalization approach neural activation constellations and a generalized framework for the final global average and bilinear pooling called Î±-pooling. We observe that the latter often achieves a higher accuracy improving common CNN models by up to 22.9%, but lacks the interpretability of the explicit approaches. We present a visualization approach for understanding and analyzing predictions of the model to address this issue. Furthermore, we show that our approaches for fine-grained recognition are beneficial for other fields like action recognition.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2019</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner19_Fully.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Fully Convolutional Networks in Multimodal Nonlinear Microscopy Images for Automated Detection of Head and Neck Carcinoma: A Pilot Study.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Thomas Bocklitz and Ferdinand von Eggeling and Günther Ernst and Olga Chernavskaia and Jürgen Popp and Joachim Denzler and Orlando Guntinas-Lichius.</span>
            <br />
            
            <span class=bibvenue>Head and Neck.</span>
            
            
            <span class=bibpages>41(1):</span>
            
            
            <span class=bibpages>116-121.</span>
            
            <span class=bibyear>2019.</span>
            
            
            
            
            <a href="/bib/Rodner19_Fully"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/hed.25489"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Rodner19_Fully');">more ...</span>
            <div class="bibabstract" id="Rodner19_Fully">
              <br />
              <div class='vspace'></div>
              Abstract: A fully convolutional neural networks (FCN)-based automated image analysis algorithm to discriminate between head and neck cancer and noncancerous epithelium based on nonlinear microscopic images was developed. Head and neck cancer sections were used for standard histopathology and co-registered with multimodal images from the same sections using the combination of coherent anti-Stokes Raman scattering, two-photon excited fluorescence, and second harmonic generation microscopy. The images analyzed with semantic segmentation using a FCN for four classes: cancer, normal epithelium, background, and other tissue types. A total of 114 images of 12 patients were analyzed. Using a patch score aggregation, the average recognition rate and an overall recognition rate or the four classes were 88.9\% and 86.7\%, respectively. A total of 113â€‰seconds were needed to process a whole-slice image in the dataset. Multimodal nonlinear microscopy in combination with automated image analysis using FCN seems to be a promising technique for objective differentiation between head and neck cancer and noncancerous epithelium.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Barz18_MDI.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Barz18_MDI.pdf">Detecting Regions of Maximal Divergence for Spatio-Temporal Anomaly Detection</a>.</span>
            <br />
            <span class=bibauthor>Björn Barz and Erik Rodner and Yanira Guanche Garcia and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>IEEE Transactions on Pattern Analysis and Machine Intelligence.</span>
            
            
            <span class=bibpages>41(5):</span>
            
            
            <span class=bibpages>1088-1101.</span>
            
            <span class=bibyear>2019.</span>
            
            
            
            <span class=note> (Pre-print published in 2018.)</span>
            
            
            <a href="/bib/Barz18_MDI"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Barz18_MDI.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="https://cvjena.github.io/libmaxdiv/"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            <a href="https://github.com/cvjena/libmaxdiv"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Barz18_MDI');">more ...</span>
            <div class="bibabstract" id="Barz18_MDI">
              <br />
              <div class='vspace'></div>
              Abstract: Automatic detection of anomalies in space- and time-varying measurements is an important tool in several fields, e.g., fraud detection, climate analysis, or healthcare monitoring. We present an algorithm for detecting anomalous regions in multivariate spatio-temporal time-series, which allows for spotting the interesting parts in large amounts of data, including video and text data. In opposition to existing techniques for detecting isolated anomalous data points, we propose the "Maximally Divergent Intervals" (MDI) framework for unsupervised detection of coherent spatial regions and time intervals characterized by a high Kullback-Leibler divergence compared with all other data given. In this regard, we define an unbiased Kullback-Leibler divergence that allows for ranking regions of different size and show how to enable the algorithm to run on large-scale data sets in reasonable time using an interval proposal technique. Experiments on both synthetic and real data from various domains, such as climate analysis, video surveillance, and text forensics, demonstrate that our method is widely applicable and a valuable tool for finding interesting events in different types of data.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2018</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Qaiser18_HIS.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              HER2 challenge contest: a detailed assessment of automated HER2 scoring algorithms in whole slide images of breast cancer tissues.</span>
            <br />
            <span class=bibauthor>Talha Qaiser and Abhik Mukherjee and Chaitanya Reddy PB and Sai D Munugoti and Vamsi Tallam and Tomi PitkÃ¤aho and Taina LehtimÃ¤ki and Thomas Naughton and Matt Berseth and AnÃ­bal Pedraza and Ramakrishnan Mukundan and Matthew Smith and Abhir Bhalerao and Erik Rodner and Marcel Simon and Joachim Denzler and Chao-Hui Huang and Gloria Bueno and David Snead and Ian O Ellis and Mohammad Ilyas and Nasir Rajpoot.</span>
            <br />
            
            <span class=bibvenue>Histopathology.</span>
            
            
            <span class=bibpages>72(2):</span>
            
            
            <span class=bibpages>227-238.</span>
            
            <span class=bibyear>2018.</span>
            
            
            
            
            <a href="/bib/Qaiser18_HIS"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="http://dx.doi.org/10.1111/his.13333"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Qaiser18_HIS');">more ...</span>
            <div class="bibabstract" id="Qaiser18_HIS">
              <br />
              <div class='vspace'></div>
              Abstract: Aims  Evaluating expression of the human epidermal growth factor receptor 2 (HER2) by visual examination of immunohistochemistry (IHC) on invasive breast cancer (BCa) is a key part of the diagnostic assessment of BCa due to its recognized importance as a predictive and prognostic marker in clinical practice. However, visual scoring of HER2 is subjective, and consequently prone to interobserver variability. Given the prognostic and therapeutic implications of HER2 scoring, a more objective method is required. In this paper, we report on a recent automated HER2 scoring contest, held in conjunction with the annual PathSoc meeting held in Nottingham in June 2016, aimed at systematically comparing and advancing the state-of-the-art artificial intelligence (AI)-based automated methods for HER2 scoring.  Methods and results  The contest data set comprised digitized whole slide images (WSI) of sections from 86 cases of invasive breast carcinoma stained with both haematoxylin and eosin (H&E) and IHC for HER2. The contesting algorithms predicted scores of the IHC slides automatically for an unseen subset of the data set and the predicted scores were compared with the â€˜ground truthâ€™ (a consensus score from at least two experts). We also report on a simple â€˜Man versus Machineâ€™ contest for the scoring of HER2 and show that the automated methods could beat the pathology experts on this contest data set.  Conclusions  This paper presents a benchmark for comparing the performance of automated algorithms for scoring of HER2. It also demonstrates the enormous potential of automated algorithms in assisting the pathologist with objective IHC scoring.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kaeding18_ALR.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kaeding18_ALR.pdf">Active Learning for Regression Tasks with Expected Model Output Changes</a>.</span>
            <br />
            <span class=bibauthor>Christoph Käding and Erik Rodner and Alexander Freytag and Oliver Mothes and Björn Barz and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>British Machine Vision Conference (BMVC).</span>
            
            <span class=bibyear>2018.</span>
            
            
            
            
            <a href="/bib/Kaeding18_ALR"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kaeding18_ALR.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            <a href="http://triton.inf-cv.uni-jena.de/LifelongLearning/gpEMOCreg"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Kaeding18_ALR');">more ...</span>
            <div class="bibabstract" id="Kaeding18_ALR">
              <br />
              <div class='vspace'></div>
              Abstract: Annotated training data is the enabler for supervised learning.  While recording data at large scale is possible in some application domains,  collecting reliable annotations is time-consuming, costly, and often a project's bottleneck.  Active learning aims at reducing the annotation effort.  While this field has been studied extensively for classification tasks, it has received less attention for regression problems  although the annotation cost is often even higher.  We aim at closing this gap and propose an active learning approach to enable regression applications.  To address continuous outputs, we build on Gaussian process models -- an established tool to tackle even non-linear regression problems.  For active learning, we extend the expected model output change (EMOC) framework to continuous label spaces and show that the involved marginalizations can be solved in closed-form.  This mitigates one of the major drawbacks of the EMOC principle.  We empirically analyze our approach in a variety of application scenarios.  In summary, we observe that our approach can efficiently guide the annotation process and leads to better models in shorter time and at lower costs.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2017</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Flach17_MAD.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Multivariate anomaly detection for Earth observations: a comparison of algorithms and feature extraction techniques.</span>
            <br />
            <span class=bibauthor>Milan Flach and Fabian Gans and Alexander Brenning and Joachim Denzler and Markus Reichstein and Erik Rodner and Sebastian Bathiany and Paul Bodesheim and Yanira Guanche and Sebasitan Sippel and Miguel D. Mahecha.</span>
            <br />
            
            <span class=bibvenue>Earth System Dynamics.</span>
            
            
            <span class=bibpages>8(3):</span>
            
            
            <span class=bibpages>677-696.</span>
            
            <span class=bibyear>2017.</span>
            
            
            
            
            <a href="/bib/Flach17_MAD"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="https://www.earth-syst-dynam.net/8/677/2017/"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/aubreville2017automatic.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Automatic Classification of Cancerous Tissue in Laserendomicroscopy Images of the Oral Cavity using Deep Learning.</span>
            <br />
            <span class=bibauthor>Marc Aubreville and Christian Knipfer and Nicolai Oetter and Christian Jaremenko and Erik Rodner and Joachim Denzler and Christopher Bohr and Helmut Neumann and Florian Stelzle and Andreas Maier.</span>
            <br />
            
            <span class=bibvenue>Scientific Reports.</span>
            
            
            <span class=bibpages>7(1):</span>
            
            
            <span class=bibpages>41598-017.</span>
            
            <span class=bibyear>2017.</span>
            
            
            
            
            <a href="/bib/aubreville2017automatic"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="https://www5.informatik.uni-erlangen.de/Forschung/Publikationen/2017/Aubreville17-ACO.pdf"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner17_DBF.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner17_DBF.pdf">Deep bilinear features for Her2 scoring in digital pathology</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Marcel Simon and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>Current Directions in Biomedical Engineering.</span>
            
            
            <span class=bibpages>3(2):</span>
            
            
            <span class=bibpages>811-814.</span>
            
            <span class=bibyear>2017.</span>
            
            
            
            
            <a href="/bib/Rodner17_DBF"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner17_DBF.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Simon17_GOP.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Simon17_GOP.pdf">Generalized orderless pooling performs implicit salient matching</a>.</span>
            <br />
            <span class=bibauthor>Marcel Simon and Yang Gao and Trevor Darrell and Joachim Denzler and Erik Rodner.</span>
            <br />
            <span class=bibvenue>International Conference on Computer Vision (ICCV).</span>
            
            <span class=bibpages>4970-4979.</span>
            
            <span class=bibyear>2017.</span>
            
            
            
            
            <a href="/bib/Simon17_GOP"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Simon17_GOP.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Barz17_MDI-Weather.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Barz17_MDI-Weather.pdf">Maximally Divergent Intervals for Extreme Weather Event Detection</a>.</span>
            <br />
            <span class=bibauthor>Björn Barz and Yanira Guanche and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>MTS/IEEE OCEANS Conference Aberdeen.</span>
            
            <span class=bibpages>1-9.</span>
            
            <span class=bibyear>2017.</span>
            
            
            
            
            <a href="/bib/Barz17_MDI-Weather"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Barz17_MDI-Weather.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Barz17_MDI-Weather');">more ...</span>
            <div class="bibabstract" id="Barz17_MDI-Weather">
              <br />
              <div class='vspace'></div>
              Abstract: We  approach  the  task  of  detecting  anomalous  or extreme events in multivariate spatio-temporal climate data using an  unsupervised  machine  learning  algorithm  for  detection  of anomalous  intervals  in  time-series.  In  contrast  to  many  existing algorithms  for  outlier  and  anomaly  detection,  our  method  does not  search  for  point-wise  anomalies,  but  for  contiguous  anomalous  intervals.  We  demonstrate  the  suitability  of  our  approach through numerous experiments on climate data, including detection  of  hurricanes,  North  Sea  storms,  and  low-pressure  fields.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner16_LGP.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner16_LGP.pdf">Large-Scale Gaussian Process Inference with Generalized Histogram Intersection Kernels for Visual Recognition Tasks</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Alexander Freytag and Paul Bodesheim and Björn Fröhlich and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>International Journal of Computer Vision (IJCV).</span>
            
            
            <span class=bibpages>121(2):</span>
            
            
            <span class=bibpages>253-280.</span>
            
            <span class=bibyear>2017.</span>
            
            
            
            
            <a href="/bib/Rodner16_LGP"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner16_LGP.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://dx.doi.org/10.1007/s11263-016-0929-y"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Barz17_FLP.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Fast Learning and Prediction for Object Detection using Whitened CNN Features.</span>
            <br />
            <span class=bibauthor>Björn Barz and Erik Rodner and Christoph Käding and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>arXiv preprint arXiv:1704.02930.</span>
            
            
            
            <span class=bibyear>2017.</span>
            
            
            
            
            <a href="/bib/Barz17_FLP"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="https://arxiv.org/abs/1704.02930"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2016</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/SimonRD16.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/SimonRD16.pdf">ImageNet pre-trained models with batch normalization</a>.</span>
            <br />
            <span class=bibauthor>Marcel Simon and Erik Rodner and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>CoRR.</span>
            
            
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/SimonRD16"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/SimonRD16.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://arxiv.org/abs/1612.01452"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('SimonRD16');">more ...</span>
            <div class="bibabstract" id="SimonRD16">
              <br />
              <div class='vspace'></div>
              Abstract: Convolutional neural networks (CNN) pre-trained on ImageNet are the backbone of most state-of-the-art approaches. In this paper, we present a new set of pretrained models with popular state-of-the-art architectures for the Caffe framework. The first release includes Residual Networks (ResNets) with generation script as well as the batch-normalization-variants of AlexNet and VGG19. All models outperform previous models with the same architecture. The models and training code are available at http://www.inf-cv.uni-jena.de/Research/CNN+Models.html and https://github.com/cvjena/cnn-models.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Campos16_BLA.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Campos16_BLA.pdf">Vegetation segmentation in cornfield images using bag of words</a>.</span>
            <br />
            <span class=bibauthor>Yerania Campos and Erik Rodner and Joachim Denzler and Humberto Sossa and Gonzalo Pajares.</span>
            <br />
            <span class=bibvenue>Advanced Concepts for Intelligent Vision Systems (ACIVS).</span>
            
            <span class=bibpages>193-204.</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Campos16_BLA"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Campos16_BLA.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="https://link.springer.com/chapter/10.1007/978-3-319-48680-2_18"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Campos16_BLA');">more ...</span>
            <div class="bibabstract" id="Campos16_BLA">
              <br />
              <div class='vspace'></div>
              Abstract: We provide an alternative methodology for vegetation segmentation in cornfield images. The process includes two main steps, which makes the main contribution of this approach: (a) a low-level segmentation and (b) a class label assignment using Bag of Words (BoW) representation in conjunction with a supervised learning framework. The experimental results show our proposal is adequate to extract green plants in images of maize fields. The accuracy for classification is 95.3 % which is comparable to values in current literature.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Denzler16_CNNA.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Denzler16_CNNA.pdf">Convolutional Neural Networks as a Computational Model for the Underlying Processes of Aesthetics Perception</a>.</span>
            <br />
            <span class=bibauthor>Joachim Denzler and Erik Rodner and Marcel Simon.</span>
            <br />
            <span class=bibvenue>ECCV Workshop on Computer Vision for Art Analysis.</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Denzler16_CNNA"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Denzler16_CNNA.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="https://www.springerprofessional.de/convolutional-neural-networks-as-a-computational-model-for-the-u/10711224"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kaeding16_ACE.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kaeding16_ACE.pdf">Active and Continuous Exploration with Deep Neural Networks and Expected Model Output Changes</a>.</span>
            <br />
            <span class=bibauthor>Christoph Käding and Erik Rodner and Alexander Freytag and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>NIPS Workshop on Continual Learning and Deep Networks (NIPS-WS).</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Kaeding16_ACE"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kaeding16_ACE.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="https://sites.google.com/site/cldlnips2016/"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Kaeding16_ACE');">more ...</span>
            <div class="bibabstract" id="Kaeding16_ACE">
              <br />
              <div class='vspace'></div>
              Abstract: The demands on visual recognition systems do not end with the complexity offered  by current large-scale image datasets, such as ImageNet. In consequence, we need  curious and continuously learning algorithms that actively acquire knowledge about  semantic concepts which are present in available unlabeled data. As a step towards  this goal, we show how to perform continuous active learning and exploration,  where an algorithm actively selects relevant batches of unlabeled examples for  annotation. These examples could either belong to already known or to yet undiscovered  classes. Our algorithm is based on a new generalization of the Expected  Model Output Change principle for deep architectures and is especially tailored to  deep neural networks. Furthermore, we show easy-to-implement approximations  that yield efficient techniques for active selection. Empirical experiments show that  our method outperforms currently used heuristics.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kaeding16_FDN.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kaeding16_FDN.pdf">Fine-tuning Deep Neural Networks in Continuous Learning Scenarios</a>.</span>
            <br />
            <span class=bibauthor>Christoph Käding and Erik Rodner and Alexander Freytag and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>ACCV Workshop on Interpretation and Visualization of Deep Neural Nets (ACCV-WS).</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Kaeding16_FDN"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kaeding16_FDN.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://www.interpretable-ml.org/accv2016workshop/"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            
            <a href="file:///Users/rodner/dev/webpage//supplementary/Kaeding16_FDN.supplementary.pdf"><img src="supplementary.png"
                alt="supplementary" title="supplementary" target="_blank" /></a>
            


            
            <span class="abstractlink" onClick="abstractclick('Kaeding16_FDN');">more ...</span>
            <div class="bibabstract" id="Kaeding16_FDN">
              <br />
              <div class='vspace'></div>
              Abstract: The revival of deep neural networks and the availability of ImageNet  laid the foundation for recent success in highly complex recognition tasks. However,  ImageNet does not cover all visual concepts of all possible application scenarios.  Hence, application experts still record new data constantly and expect the  data to be used upon its availability. In this paper, we follow this observation  and apply the classical concept of fine-tuning deep neural networks to scenarios  where data from known or completely new classes is continuously added.  Besides a straightforward realization of continuous fine-tuning, we empirically  analyze how computational burdens of training can be further reduced. Finally,  we visualize how the networkâ€™s attention maps evolve over time which allows for  visually investigating what the network learned during continuous fine-tuning.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Jaeger16_OPC.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Jaeger16_OPC.pdf">SeaCLEF 2016: Object Proposal Classification for Fish Detection in Underwater Videos</a>.</span>
            <br />
            <span class=bibauthor>Jonas Jäger and Erik Rodner and Joachim Denzler and Viviane Wolff and Klaus Fricke-Neuderth.</span>
            <br />
            <span class=bibvenue>Working Notes of CLEF 2016 - Conference and Labs of the Evaluation forum.</span>
            
            <span class=bibpages>481-489.</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Jaeger16_OPC"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Jaeger16_OPC.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Amthor16_IDD.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Amthor16_IDD.pdf">Impatient DNNs - Deep Neural Networks with Dynamic Time Budgets</a>.</span>
            <br />
            <span class=bibauthor>Manuel Amthor and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>British Machine Vision Conference (BMVC).</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Amthor16_IDD"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Amthor16_IDD.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner16_FRN.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner16_FRN.pdf">Fine-grained Recognition in the Noisy Wild: Sensitivity Analysis of Convolutional Neural Networks Approaches</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Marcel Simon and Bob Fisher and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>British Machine Vision Conference (BMVC).</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Rodner16_FRN"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner16_FRN.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            
            <a href="file:///Users/rodner/dev/webpage//supplementary/Rodner16_FRN.supplementary.pdf"><img src="supplementary.png"
                alt="supplementary" title="supplementary" target="_blank" /></a>
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kaeding16_LAA.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kaeding16_LAA.pdf">Large-scale Active Learning with Approximated Expected Model Output Changes</a>.</span>
            <br />
            <span class=bibauthor>Christoph Käding and Alexander Freytag and Erik Rodner and Andrea Perino and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>German Conference on Pattern Recognition (GCPR).</span>
            
            <span class=bibpages>179-191.</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Kaeding16_LAA"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kaeding16_LAA.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="https://link.springer.com/chapter/10.1007/978-3-319-45886-1_15"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            <a href="http://triton.inf-cv.uni-jena.de/LifelongLearning/gpEMOC"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            
            <a href="file:///Users/rodner/dev/webpage//supplementary/Kaeding16_LAA.supplementary.pdf"><img src="supplementary.png"
                alt="supplementary" title="supplementary" target="_blank" /></a>
            


            
            <span class="abstractlink" onClick="abstractclick('Kaeding16_LAA');">more ...</span>
            <div class="bibabstract" id="Kaeding16_LAA">
              <br />
              <div class='vspace'></div>
              Abstract: Incremental learning of visual concepts is one step towards reaching human capabilities beyond closed-world assumptions. Besides recent progress, it remains one of the fundamental challenges in computer vision and machine learning. Along that path, techniques are needed which allow for actively selecting informative examples from a huge pool of unlabeled images to be annotated by application experts. Whereas a manifold of active learning techniques exists, they commonly suffer from one of two drawbacks: (i) either they do not work reliably on challenging real-world data or (ii) they are kernel-based and not scalable with the magnitudes of data current vision applications need to deal with. Therefore, we present an active learning and discovery approach which can deal with huge collections of unlabeled real-world data. Our approach is based on the expected model output change principle and overcomes previous scalability issues. We present experiments on the large-scale MS-COCO dataset and on a dataset provided by biodiversity researchers. Obtained results reveal that our technique clearly improves accuracy after just a few annotations. At the same time, it outperforms previous active learning approaches in academic and real-world scenarios.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Freytag16_CFW.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Freytag16_CFW.pdf">Chimpanzee Faces in the Wild: Log-Euclidean CNNs for Predicting Identities and Attributes of Primates</a>.</span>
            <br />
            <span class=bibauthor>Alexander Freytag and Erik Rodner and Marcel Simon and Alexander Loos and Hjalmar Kühl and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>German Conference on Pattern Recognition (GCPR).</span>
            
            <span class=bibpages>51-63.</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Freytag16_CFW"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Freytag16_CFW.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="https://link.springer.com/chapter/10.1007/978-3-319-45886-1_5"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            
            <a href="file:///Users/rodner/dev/webpage//supplementary/Freytag16_CFW.supplementary.pdf"><img src="supplementary.png"
                alt="supplementary" title="supplementary" target="_blank" /></a>
            


            
            <span class="abstractlink" onClick="abstractclick('Freytag16_CFW');">more ...</span>
            <div class="bibabstract" id="Freytag16_CFW">
              <br />
              <div class='vspace'></div>
              Abstract: In this paper, we investigate how to predict attributes of chimpanzees such as identity, age, age group, and gender. We build on convolutional neural networks, which lead to significantly superior results compared with previous state-of-the-art on hand-crafted recognition pipelines. In addition, we show how to further increase discrimination abilities of CNN activations by the Log-Euclidean framework on top of bilinear pooling. We finally introduce two curated datasets consisting of chimpanzee faces with detailed meta-information to stimulate further research. Our results can serve as the foundation for automated large-scale animal monitoring and analysis.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Guanche16_DMB.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Detecting Multivariate Biosphere Extremes.</span>
            <br />
            <span class=bibauthor>Yanira Guanche Garcia and Erik Rodner and Milan Flach and Sebastian Sippel and Miguel Mahecha and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>International Workshop on Climate Informatics (CI).</span>
            
            <span class=bibpages>9-12.</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Guanche16_DMB"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="http://dx.doi.org/10.5065/D6K072N6"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Guanche16_DMB');">more ...</span>
            <div class="bibabstract" id="Guanche16_DMB">
              <br />
              <div class='vspace'></div>
              Abstract: The detection of anomalies in multivariate time series is crucial to identify changes in the ecosystems. We propose an intuitive methodology to assess the occurrence of tail events of multiple biosphere variables.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner16_MDI.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner16_MDI.pdf">Maximally Divergent Intervals for Anomaly Detection</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Björn Barz and Yanira Guanche and Milan Flach and Miguel Mahecha and Paul Bodesheim and Markus Reichstein and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>ICML Workshop on Anomaly Detection (ICML-WS).</span>
            
            <span class=bibyear>2016.</span>
            
            
            <span class=awardnote> Best Paper Award</span>
            
            <a href="/bib/Rodner16_MDI"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner16_MDI.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            <a href="https://cvjena.github.io/libmaxdiv/"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kaeding16_WALI.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kaeding16_WALI.pdf">Watch, Ask, Learn, and Improve: A Lifelong Learning Cycle for Visual Recognition</a>.</span>
            <br />
            <span class=bibauthor>Christoph Käding and Erik Rodner and Alexander Freytag and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>European Symposium on Artificial Neural Networks (ESANN).</span>
            
            <span class=bibpages>381-386.</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Kaeding16_WALI"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kaeding16_WALI.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            <a href="http://triton.inf-cv.uni-jena.de/LifelongLearning/gpEMOC"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Kaeding16_WALI.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            


            
            <span class="abstractlink" onClick="abstractclick('Kaeding16_WALI');">more ...</span>
            <div class="bibabstract" id="Kaeding16_WALI">
              <br />
              <div class='vspace'></div>
              Abstract: We present WALI, a prototypical system that learns object categories  over time by continuously watching online videos. WALI actively asks questions  to a human annotator about the visual content of observed video frames. Thereby,  WALI is able to receive information about new categories and to simultaneously  improve its generalization abilities. The functionality of WALI is driven by scalable  active learning, efficient incremental learning, as well as state-of-the-art visual descriptors.  In our experiments, we show qualitative and quantitative statistics about  WALI's learning process. WALI runs continuously and regularly asks questions.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Brust16_EQL.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Brust16_EQL.pdf">Neither Quick Nor Proper -- Evaluation of QuickProp for Learning Deep Neural Networks</a>.</span>
            <br />
            <span class=bibauthor>Clemens-Alexander Brust and Sven Sickert and Marcel Simon and Erik Rodner and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>arXiv preprint arXiv:1606.04333.</span>
            
            
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Brust16_EQL"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Brust16_EQL.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="https://arxiv.org/abs/1606.04333"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Brust16_EQL');">more ...</span>
            <div class="bibabstract" id="Brust16_EQL">
              <br />
              <div class='vspace'></div>
              Abstract: Neural networks and especially convolutional neural networks are of great  interest in current computer vision research. However, many techniques, extensions,  and modifications have been published in the past, which are not yet used by  current approaches. In this paper, we study the application of a method called  QuickProp for training of deep neural networks. In particular, we apply QuickProp  during learning and testing of fully convolutional networks for the task of  semantic segmentation. We compare QuickProp empirically with gradient descent,  which is the current standard method. Experiments suggest that QuickProp can not  compete with standard gradient descent techniques for complex computer vision  tasks like semantic segmentation.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Flach16_USP.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Flach16_USP.pdf">Using Statistical Process Control for detecting anomalies in multivariate spatiotemporal Earth Observations</a>.</span>
            <br />
            <span class=bibauthor>Milan Flach and Miguel Mahecha and Fabian Gans and Erik Rodner and Paul Bodesheim and Yanira Guanche-Garcia and Alexander Brenning and Joachim Denzler and Markus Reichstein.</span>
            <br />
            <span class=bibvenue>European Geosciences Union General Assembly.</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Flach16_USP"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Flach16_USP.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://meetingorganizer.copernicus.org/EGU2016/EGU2016-7948-2.pdf"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Multivariate Anomaly Detection for Earth Observations: A Comparison of Algorithms and Feature Extraction Techniques.</span>
            <br />
            <span class=bibauthor>Milan Flach and Fabian Gans and Alexander Brenning and Joachim Denzler and Markus Reichstein and Erik Rodner and Sebastian Bathiany and Paul Bodesheim and Yanira Garcia Guanche and Sebastian Sippel and Miguel Mahecha.</span>
            <br />
            
            <span class=bibvenue>Earth System Dynamics.</span>
            
            
            
            <span class=bibyear>2016.</span>
            
            
            
            <span class=note> in discussion</span>
            
            
            <a href="/bib/Flach16_MAD"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="http://www.earth-syst-dynam-discuss.net/esd-2016-51/"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Sickert16_SVS.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Sickert16_SVS.pdf">Semantic Volume Segmentation with Iterative Context Integration for Bio-medical Image Stacks</a>.</span>
            <br />
            <span class=bibauthor>Sven Sickert and Erik Rodner and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>Pattern Recognition and Image Analysis. Advances in Mathematical  Theory and Applications (PRIA).</span>
            
            
            <span class=bibpages>26(1):</span>
            
            
            <span class=bibpages>197-204.</span>
            
            <span class=bibyear>2016.</span>
            
            
            
            
            <a href="/bib/Sickert16_SVS"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Sickert16_SVS.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Sickert16_SVS');">more ...</span>
            <div class="bibabstract" id="Sickert16_SVS">
              <br />
              <div class='vspace'></div>
              Abstract: Automatic recognition of biological structures like membranes or synapses  is important to analyze organic processes and to understand their  functional behavior. To achieve this, volumetric images taken by  electron microscopy or computer tomography have to be segmented into  meaningful semantic regions. We are extending iterative context forests  which were developed for 2D image data to image stack segmentation.  In particular, our method is able to learn high-order dependencies and  import contextual information, which often can not be learned by conventional  Markov random field approaches usually used for this task. Our method is  tested on very different and challenging medical and biological segmentation  tasks.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2015</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Guadarrama15_UOD.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Guadarrama15_UOD.pdf">Understanding Object Descriptions in Robotics by Open-vocabulary Object Retrieval and Detection</a>.</span>
            <br />
            <span class=bibauthor>Sergio Guadarrama and Erik Rodner and Kate Saenko and Trevor Darrell.</span>
            <br />
            
            <span class=bibvenue>International Journal of Robotics Research (IJRR).</span>
            
            
            <span class=bibpages>35(1-3):</span>
            
            
            <span class=bibpages>265-280.</span>
            
            <span class=bibyear>2015.</span>
            
            
            
            
            <a href="/bib/Guadarrama15_UOD"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Guadarrama15_UOD.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://ijr.sagepub.com/content/35/1-3/265.abstract"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner15_ACM.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner15_ACM.pdf">Analysis and Classification of Microscopy Images with Cell Border Distance Statistics</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Wolfgang Ortmann and Andreas Dittberner and  Joachim Stadler and Carsten Schmidt and Iver Petersen and Andreas Stallmach  and Joachim Denzler and Orlando Guntinas-Lichius.</span>
            <br />
            <span class=bibvenue>Jahrestagung der Deutschen Gesellschaft für Medizinische Physik (DGMP).</span>
            
            <span class=bibyear>2015.</span>
            
            
            
            
            <a href="/bib/Rodner15_ACM"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner15_ACM.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Dittberner15_AAC.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Automated analysis of confocal laser endomicroscopy images to detect head and neck cancer.</span>
            <br />
            <span class=bibauthor>Andreas Dittberner and Erik Rodner and Wolfgang Ortmann and Joachim Stadler and  Carsten Schmidt and Iver Petersen and Andreas Stallmach and Joachim Denzler and Orlando Guntinas-Lichius.</span>
            <br />
            
            <span class=bibvenue>Head and Neck.</span>
            
            
            <span class=bibpages>38(1):</span>
            
            
            <span class=bibyear>2015.</span>
            
            
            
            
            <a href="/bib/Dittberner15_AAC"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="http://onlinelibrary.wiley.com/doi/10.1002/hed.24253/abstract;jsessionid=9C525879C44676D6CE47CFC244ADA853.f01t04"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kaeding15_ALD.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kaeding15_ALD.pdf">Active Learning and Discovery of Object Categories in the Presence of Unnameable Instances</a>.</span>
            <br />
            <span class=bibauthor>Christoph Käding and Alexander Freytag and Erik Rodner and Paul Bodesheim and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</span>
            
            <span class=bibpages>4343-4352.</span>
            
            <span class=bibyear>2015.</span>
            
            
            
            
            <a href="/bib/Kaeding15_ALD"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kaeding15_ALD.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Kading_Active_Learning_and_2015_CVPR_paper.html"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            <a href="http://triton.inf-cv.uni-jena.de/LifelongLearning/gpEMOC"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Kaeding15_ALD.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            
            <a href="file:///Users/rodner/dev/webpage//supplementary/Kaeding15_ALD.supplementary.pdf"><img src="supplementary.png"
                alt="supplementary" title="supplementary" target="_blank" /></a>
            


            
            <span class="abstractlink" onClick="abstractclick('Kaeding15_ALD');">more ...</span>
            <div class="bibabstract" id="Kaeding15_ALD">
              <br />
              <div class='vspace'></div>
              Abstract: Current visual recognition algorithms are "hungry" for data but massive annotation is extremely costly. Therefore, active learning algorithms are required that reduce labeling efforts to a minimum by selecting examples that are most valuable for labeling. In active learning, all categories occurring in collected data are usually assumed to be known in advance and experts should be able to label every requested instance. But do these assumptions really hold in practice? Could you name all categories in every image? Existing algorithms completely ignore the fact that there are certain examples where an oracle can not provide an answer or which even do not belong to the current problem domain. Ideally, active learning techniques should be able to discover new classes and at the same time cope with queries an expert is not able or willing to label. To meet these observations, we present a variant of the expected model output change principle for active learning and discovery in the presence of  unnameable instances. Our experiments show that in these realistic scenarios, our approach substantially outperforms previous active learning methods, which are often not even able to improve with respect to the baseline of random query selection.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Bodesheim15_LND.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Bodesheim15_LND.pdf">Local Novelty Detection in Multi-class Recognition Problems</a>.</span>
            <br />
            <span class=bibauthor>Paul Bodesheim and Alexander Freytag and Erik Rodner and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>IEEE Winter Conference on Applications of Computer  Vision (WACV).</span>
            
            <span class=bibpages>813-820.</span>
            
            <span class=bibyear>2015.</span>
            
            
            
            
            <a href="/bib/Bodesheim15_LND"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Bodesheim15_LND.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            
            <a href="file:///Users/rodner/dev/webpage//supplementary/Bodesheim15_LND.supplementary.pdf"><img src="supplementary.png"
                alt="supplementary" title="supplementary" target="_blank" /></a>
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Simon15_NAC.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Simon15_NAC.pdf">Neural Activation Constellations: Unsupervised Part Model Discovery with Convolutional Networks</a>.</span>
            <br />
            <span class=bibauthor>Marcel Simon and Erik Rodner.</span>
            <br />
            <span class=bibvenue>International Conference on Computer Vision (ICCV).</span>
            
            <span class=bibpages>1143-1151.</span>
            
            <span class=bibyear>2015.</span>
            
            
            
            
            <a href="/bib/Simon15_NAC"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Simon15_NAC.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://arxiv.org/abs/1504.08289"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Simon15_NAC');">more ...</span>
            <div class="bibabstract" id="Simon15_NAC">
              <br />
              <div class='vspace'></div>
              Abstract: Part models of object categories are essential for challenging recognition tasks, where differences in categories are subtle and only reflected in appearances of small parts of the object. We present an approach that is able to learn part models in a completely unsupervised manner, without part annotations and even without given bounding boxes during learning. The key idea is to find constellations of neural activation patterns computed using convolutional neural networks. In our experiments, we outperform existing approaches for fine-grained recognition on the CUB200-2011, Oxford PETS, and Oxford Flowers dataset in case no part or bounding box annotations are available and achieve state-of-the-art performance for the Stanford Dog dataset. We also show the benefits of neural constellation models as a data augmentation technique for fine-tuning. Furthermore, our paper unites the areas of generic and fine-grained classification, since our approach is suitable for both scenarios.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Brust15_CPN.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Brust15_CPN.pdf">Convolutional Patch Networks with Spatial Prior for Road Detection and Urban Scene Understanding</a>.</span>
            <br />
            <span class=bibauthor>Clemens-Alexander Brust and Sven Sickert and Marcel Simon and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>International Conference on Computer Vision Theory and Applications (VISAPP).</span>
            
            <span class=bibpages>510-517.</span>
            
            <span class=bibyear>2015.</span>
            
            
            
            
            <a href="/bib/Brust15_CPN"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Brust15_CPN.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://arxiv.org/abs/1502.06344"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            <a href="http://cvjena.github.io/cn24/"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Brust15_CPN');">more ...</span>
            <div class="bibabstract" id="Brust15_CPN">
              <br />
              <div class='vspace'></div>
              Abstract: Classifying single image patches is important in many different applications, such as road detection or scene understanding.  In this paper, we present convolutional patch networks, which are convolutional networks learned to distinguish different image patches and  which can be used for pixel-wise labeling.  We also show how to incorporate spatial information of the patch as an input to the network, which allows for learning spatial priors for  certain categories jointly with an appearance model.  In particular, we focus on road detection and urban scene understanding, two application areas where we are able to achieve state-of-the-art  results on  the KITTI as well as on the LabelMeFacade dataset.  Furthermore, our paper offers a guideline for people working in the area and desperately wandering through all the painstaking details that  render training CNs on image patches extremely difficult.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner15_FRD.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner15_FRD.pdf">Fine-grained Recognition Datasets for Biodiversity Analysis</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Marcel Simon and Gunnar Brehm and Stephanie Pietsch and J. Wolfgang Wägele and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>CVPR Workshop on Fine-grained Visual Classification (CVPR-WS).</span>
            
            <span class=bibyear>2015.</span>
            
            
            
            
            <a href="/bib/Rodner15_FRD"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner15_FRD.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://www.inf-cv.uni-jena.de/fgvcbiodiv"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Brust15_ECP.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Brust15_ECP.pdf">Efficient Convolutional Patch Networks for Scene Understanding</a>.</span>
            <br />
            <span class=bibauthor>Clemens-Alexander Brust and Sven Sickert and Marcel Simon and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>CVPR Workshop on Scene Understanding (CVPR-WS).</span>
            
            <span class=bibyear>2015.</span>
            
            
            
            
            <a href="/bib/Brust15_ECP"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Brust15_ECP.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            <a href="http://cvjena.github.io/cn24/"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Brust15_ECP.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            


            
            <span class="abstractlink" onClick="abstractclick('Brust15_ECP');">more ...</span>
            <div class="bibabstract" id="Brust15_ECP">
              <br />
              <div class='vspace'></div>
              Abstract: In this paper, we present convolutional patch networks, which are convolutional (neural) networks (CNN) learned to distinguish  different image patches and which can be used for pixel-wise labeling. We show how to easily learn spatial priors for certain categories jointly  with their appearance. Experiments for urban scene understanding demonstrate state-of-the-art results on the LabelMeFacade dataset. Our approach  is implemented as a new CNN framework especially designed for semantic segmentation with fully-convolutional architectures.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Ruehle15_BYC.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Ruehle15_BYC.pdf">Beyond Thinking in Common Categories: Predicting Obstacle Vulnerability using Large Random Codebooks</a>.</span>
            <br />
            <span class=bibauthor>Johannes Rühle and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Machine Vision Applications (MVA).</span>
            
            <span class=bibpages>198-201.</span>
            
            <span class=bibyear>2015.</span>
            
            
            
            
            <a href="/bib/Ruehle15_BYC"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Ruehle15_BYC.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://www.mva-org.jp/mva2015/FinalProgram_20150423_clean.pdf"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Ruehle15_BYC');">more ...</span>
            <div class="bibabstract" id="Ruehle15_BYC">
              <br />
              <div class='vspace'></div>
              Abstract: Obstacle detection for advanced driver assistance systems has focused on building detectors for only a few number of categories so far, such as pedestrians and cars.  However, vulnerable obstacles of other categories are often dismissed, such as wheel-chairs and baby strollers. In our work, we try to tackle this limitation by presenting an approach which is able to predict the vulnerability of an arbitrary obstacle independently from its category. This allows for using models not specifically tuned for category recognition. To classify the vulnerability, we apply a generic category-free approach based on large random bag-of-visual-words representations (BoW), where  we make use of both the intensity image as well as a given disparity map.  In experimental results, we achieve a classification accuracy of over 80% for predicting one of four vulnerability levels for each of the 10000 obstacle hypotheses detected in a challenging dataset of real urban street scenes. Vulnerability prediction in general and our working algorithm in particular, pave the way to more advanced reasoning in autonomous driving, emergency route planning,  as well as reducing the false-positive rate of obstacle warning systems.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Simon15_FCI.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Simon15_FCI.pdf">Fine-grained Classification of Identity Document Types with Only One Example</a>.</span>
            <br />
            <span class=bibauthor>Marcel Simon and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Machine Vision Applications (MVA).</span>
            
            <span class=bibpages>126 - 129.</span>
            
            <span class=bibyear>2015.</span>
            
            
            
            
            <a href="/bib/Simon15_FCI"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Simon15_FCI.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://www.mva-org.jp/mva2015/FinalProgram_20150423_clean.pdf"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Simon15_FCI');">more ...</span>
            <div class="bibabstract" id="Simon15_FCI">
              <br />
              <div class='vspace'></div>
              Abstract: This paper shows how to recognize types of identity documents, such as passports, using state-of-the-art visual recognition approaches. Whereas recognizing individual parts on identity documents with a standardized layout is one of the old classics in computer vision, recognizing the type of the document and therefore also the layout is a challenging problem due to the large variation of the documents.  In our paper, we evaluate different techniques for this application including feature representations based on recent achievements with convolutional neural networks.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2014</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Barz14_ART.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Barz14_ART.pdf">ARTOS -- Adaptive Real-Time Object Detection System</a>.</span>
            <br />
            <span class=bibauthor>Björn Barz and Erik Rodner and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>arXiv preprint arXiv:1407.2721.</span>
            
            
            
            <span class=bibyear>2014.</span>
            
            
            
            
            <a href="/bib/Barz14_ART"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Barz14_ART.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://arxiv.org/abs/1407.2721"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            <a href="http://cvjena.github.io/artos/"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Barz14_ART');">more ...</span>
            <div class="bibabstract" id="Barz14_ART">
              <br />
              <div class='vspace'></div>
              Abstract: ARTOS is all about creating, tuning, and applying object detection  models with just a few clicks. In particular, ARTOS facilitates learning  of models for visual object detection by eliminating the burden of  having to collect and annotate a large set of positive and negative  samples manually and in addition it implements a fast learning technique  to reduce the time needed for the learning step. A clean and friendly  GUI guides the user through the process of model creation, adaptation  of learned models to different domains using in-situ images, and  object detection on both offline images and images from a video stream.  A library written in C++ provides the main functionality of ARTOS  with a C-style procedural interface, so that it can be easily integrated  with any other project.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Freytag14_STB.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Freytag14_STB.pdf">Seeing through bag-of-visual-word glasses: towards understanding  quantization effects in feature extraction methods</a>.</span>
            <br />
            <span class=bibauthor>Alexander Freytag and Johannes Rühle and Paul Bodesheim and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>International Conference on Pattern Recognition (ICPR) - FEAST workshop.</span>
            
            <span class=bibyear>2014.</span>
            
            
            <span class=awardnote> Best Poster Award</span>
            
            <a href="/bib/Freytag14_STB"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Freytag14_STB.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            <a href="https://github.com/cvjena/bowInversion"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Freytag14_STB.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            


            
            <span class="abstractlink" onClick="abstractclick('Freytag14_STB');">more ...</span>
            <div class="bibabstract" id="Freytag14_STB">
              <br />
              <div class='vspace'></div>
              Abstract: The bag-of-visual-word (BoW) model is one of the most common concepts for image categorization and feature extraction.  Although our community developed powerful BoW approaches for visual recognition  and it serves as a great ad-hoc solution, unfortunately, there are several drawbacks that most researchers might be not aware of.  In this paper, we aim at seeing behind the curtains and point to some of the negative aspects of these approaches which  go usually unnoticed:  (i) although BoW approaches are often motivated by relating clusters to meaningful object parts, this relation does not hold in practice with low-dimensional features such as HOG, and standard  clustering method,  (ii) clusters can be chosen randomly without loss in performance,  (iii) BoW is often only collecting background statistics, and  (iv) cluster assignments are not robust to small spatial shifts.  Furthermore, we show the effect of BoW quantization and the related loss of visual information by a simple inversion method called HoggleBoW.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Freytag14_ESP.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Freytag14_ESP.pdf">Exemplar-specific Patch Features for Fine-grained Recognition</a>.</span>
            <br />
            <span class=bibauthor>Alexander Freytag and Erik Rodner and Trevor Darrell and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>German Conference on Pattern Recognition (GCPR).</span>
            
            <span class=bibpages>144-156.</span>
            
            <span class=bibyear>2014.</span>
            
            
            
            
            <a href="/bib/Freytag14_ESP"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Freytag14_ESP.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            <a href="https://github.com/cvjena/patchDiscovery"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            
            <a href="file:///Users/rodner/dev/webpage//supplementary/Freytag14_ESP.supplementary.pdf"><img src="supplementary.png"
                alt="supplementary" title="supplementary" target="_blank" /></a>
            


            
            <span class="abstractlink" onClick="abstractclick('Freytag14_ESP');">more ...</span>
            <div class="bibabstract" id="Freytag14_ESP">
              <br />
              <div class='vspace'></div>
              Abstract: In this paper, we present a new approach for fine-grained recognition or subordinate categorization,  tasks where an algorithm needs to reliably differentiate between visually similar categories, e.g. different bird species.  While previous approaches aim at learning a single generic representation and models with increasing complexity,  we propose an orthogonal approach that learns patch representations specifically tailored to every single test exemplar.  Since we query a constant number of images similar to a given test image,  we obtain very compact features and avoid large-scale training with all classes and examples.  Our learned mid-level features are build on shape and color detectors estimated from discovered patches reflecting small highly discriminative structures in the queried images.  We evaluate our approach for fine-grained recognition on the CUB-2011 birds dataset and show that high recognition rates can be obtained by model combination.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Freytag14_BFF.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Freytag14_BFF.pdf">Birds of a Feather Flock Together - Local Learning of Mid-level Representations  for Fine-grained Recognition</a>.</span>
            <br />
            <span class=bibauthor>Alexander Freytag and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>ECCV Workshop on Parts and Attributes (ECCV-WS).</span>
            
            <span class=bibyear>2014.</span>
            
            
            
            
            <a href="/bib/Freytag14_BFF"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Freytag14_BFF.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="https://filebox.ece.vt.edu/~parikh/PnA2014/"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            <a href="https://github.com/cvjena/patchDiscovery"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Freytag14_BFF.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Freytag14_SIE.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Freytag14_SIE.pdf">Selecting Influential Examples: Active Learning with Expected Model  Output Changes</a>.</span>
            <br />
            <span class=bibauthor>Alexander Freytag and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>European Conference on Computer Vision (ECCV).</span>
            
            <span class=bibpages>562-577.</span>
            
            <span class=bibyear>2014.</span>
            
            
            
            
            <a href="/bib/Freytag14_SIE"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Freytag14_SIE.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Freytag14_SIE.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            
            <a href="file:///Users/rodner/dev/webpage//supplementary/Freytag14_SIE.supplementary.pdf"><img src="supplementary.png"
                alt="supplementary" title="supplementary" target="_blank" /></a>
            


            
            <span class="abstractlink" onClick="abstractclick('Freytag14_SIE');">more ...</span>
            <div class="bibabstract" id="Freytag14_SIE">
              <br />
              <div class='vspace'></div>
              Abstract: In this paper, we introduce a new general strategy for active learning.  The key idea of our approach is to measure the expected change of model outputs, a concept  that generalizes previous methods based on expected model change and incorporates the underlying data distribution.  For each example of an unlabeled set, the expected change of model predictions  is calculated and marginalized over the unknown label. This results in a score for each unlabeled example  that can be used for active learning with a broad range of models and learning algorithms.  In particular, we show how to derive very efficient active learning methods for Gaussian process regression, which  implement this general strategy, and link them to previous methods.  We analyze our algorithms and compare them to a broad range of previous active learning strategies in experiments showing that  they outperform state-of-the-art on well-established benchmark datasets in the area of visual object recognition.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Goehring14_ITR.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Goehring14_ITR.pdf">Interactive Adaptation of Real-Time Object Detectors</a>.</span>
            <br />
            <span class=bibauthor>Daniel Göhring and Judy Hoffman and Erik Rodner and Kate Saenko  and Trevor Darrell.</span>
            <br />
            <span class=bibvenue>International Conference on Robotics and Automation (ICRA).</span>
            
            <span class=bibpages>1282-1289.</span>
            
            <span class=bibyear>2014.</span>
            
            
            
            
            <a href="/bib/Goehring14_ITR"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Goehring14_ITR.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://raptor.berkeleyvision.org/"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Goehring14_ITR');">more ...</span>
            <div class="bibabstract" id="Goehring14_ITR">
              <br />
              <div class='vspace'></div>
              Abstract: In the following paper, we present a framework for quickly training  2D object detectors for robotic perception. Our method can be used  by robotics practitioners to quickly (under 30 seconds per object)  build a large-scale real-time perception system. In particular, we  show how to create new detectors on the fly using large-scale internet  image databases, thus allowing a user to choose among thousands of  available categories to build a detection system suitable for the  particular robotic application. Furthermore, we show how to adapt  these models to the current environment with just a few in-situ images.  Experiments on existing 2D benchmarks evaluate the speed, accuracy,  and flexibility of our system.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Guadarrama14_OOR.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Guadarrama14_OOR.pdf">Open-vocabulary Object Retrieval</a>.</span>
            <br />
            <span class=bibauthor>Sergio Guadarrama and Erik Rodner and Kate Saenko and Ning Zhang  and Ryan Farrell and Jeff Donahue and Trevor Darrell.</span>
            <br />
            <span class=bibvenue>Robotics Science and Systems (RSS).</span>
            
            <span class=bibpages>41, ISBN 978-0-9923747-0-9.</span>
            
            <span class=bibyear>2014.</span>
            
            
            <span class=awardnote> Awarded with an AAAI invited talk</span>
            
            <a href="/bib/Guadarrama14_OOR"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Guadarrama14_OOR.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://openvoc.berkeleyvision.org"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Guadarrama14_OOR');">more ...</span>
            <div class="bibabstract" id="Guadarrama14_OOR">
              <br />
              <div class='vspace'></div>
              Abstract: In this paper, we address the problem of retrieving objects based  on open-vocabulary natural language queries: Given a phrase describing  a specific object, e.g., the corn flakes box, the task is to find  the best match in a set of images containing candidate objects. When  naming objects, humans tend to use natural language with rich semantics,  including basic-level categories, fine-grained categories, and instance-level  concepts such as brand names. Existing approaches to large-scale  object recognition fail in this scenario, as they expect queries  that map directly to a fixed set of pre-trained visual categories,  e.g. ImageNet synset tags. We address this limitation by introducing  a novel object retrieval method. Given a candidate object image,  we first map it to a set of words that are likely to describe it,  using several learned image-to-text projections. We also propose  a method for handling open-vocabularies, i.e., words not contained  in the training data. We then compare the natural language query  to the sets of words predicted for each candidate and select the  best match. Our method can combine category- and instance-level semantics  in a common representation. We present extensive experimental results  on several datasets using both instance-level and category-level  matching and show that our approach can accurately retrieve objects  based on extremely varied open-vocabulary queries. The source code  of our approach will be publicly available together with pre-trained  models and could be directly used for robotics applications.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Haase14_ITL.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Haase14_ITL.pdf">Instance-weighted Transfer Learning of Active Appearance Models</a>.</span>
            <br />
            <span class=bibauthor>Daniel Haase and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</span>
            
            <span class=bibpages>1426-1433.</span>
            
            <span class=bibyear>2014.</span>
            
            
            
            
            <a href="/bib/Haase14_ITL"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Haase14_ITL.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Haase14_ITL');">more ...</span>
            <div class="bibabstract" id="Haase14_ITL">
              <br />
              <div class='vspace'></div>
              Abstract: There has been a lot of work on face modeling, analysis, and landmark  detection, with Active Appearance Models being one of the most successful  techniques. A major drawback of these models is the large number  of detailed annotated training examples needed for learning. Therefore,  we present a transfer learning method that is able to learn from  related training data using an instance-weighted transfer technique.  Our method is derived using a generalization of importance sampling  and in contrast to previous work we explicitly try to tackle the  transfer already during learning instead of adapting the fitting  process. In our studied application of face landmark detection, we  efficiently transfer facial expressions from other human individuals  and are thus able to learn a precise face Active Appearance Model  only from neutral faces of a single individual. Our approach is evaluated  on two common face datasets and outperforms previous transfer methods.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Hoffman14_ACI.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Hoffman14_ACI.pdf">Asymmetric and Category Invariant Feature Transformations for Domain  Adaptation</a>.</span>
            <br />
            <span class=bibauthor>Judy Hoffman and Erik Rodner and Jeff Donahue and Brian Kulis and  Kate Saenko.</span>
            <br />
            
            <span class=bibvenue>International Journal of Computer Vision (IJCV).</span>
            
            
            <span class=bibpages>109(1-2):</span>
            
            
            <span class=bibpages>28-41.</span>
            
            <span class=bibyear>2014.</span>
            
            
            
            
            <a href="/bib/Hoffman14_ACI"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Hoffman14_ACI.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://link.springer.com/article/10.1007/s11263-014-0719-3"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Hoffman14_ACI');">more ...</span>
            <div class="bibabstract" id="Hoffman14_ACI">
              <br />
              <div class='vspace'></div>
              Abstract: We address the problem of visual domain adaptation for transferring  object models from one dataset or visual domain to another. We introduce  a unified flexible model for both supervised and semi-supervised  learning that allows us to learn transformations between domains.  Additionally, we present two instantiations of the model, one for  general feature adaptation/alignment, and one specifically designed  for classification. First, we show how to extend metric learning  methods for domain adaptation, allowing for learning metrics independent  of the domain shift and the final classifier used. Furthermore, we  go beyond classical metric learning by extending the method to asymmetric,  category independent transformations. Our framework can adapt features  even when the target domain does not have any labeled examples for  some categories, and when the target and source features have different  dimensions. Finally, we develop a joint learning framework for adaptive  classifiers, which outperforms competing methods in terms of multi-class  accuracy and scalability. We demonstrate the ability of our approach  to adapt object recognition models under a variety of situations,  such as differing imaging conditions, feature types, and codebooks.  The experiments show its strong performance compared to previous  approaches and its applicability to large-scale scenarios.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Suesse14_BV.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              Bildverarbeitung und Objekterkennung: Computer Vision in Industrie  und Medizin.</span>
            <br />
            <span class=bibauthor>Herbert Süße and Erik Rodner.</span>
            <br />
            
            
            
            <span class=bibyear>2014.</span>
            
            
            
            <span class=note> Neues umfangreiches Lehrbuch im Bereich Bildverarbeitung und maschinelles  Lernen</span>
            
            
            <a href="/bib/Suesse14_BV"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            <a href="http://www.dbvbuch.de"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Suesse14_BV');">more ...</span>
            <div class="bibabstract" id="Suesse14_BV">
              <br />
              <div class='vspace'></div>
              Abstract: Dieses Buch erlaeutert, wie Informationen automatisch aus Bildern  extrahiert werden. Mit dieser sehr aktuellen Frage beschaeftigt sich  das Buch mittels eines Streifzuges durch die Bildverarbeitung. Dabei  werden sowohl die mathematischen Grundlagen vieler Verfahren der  2D- und 3D Bildanalyse vermittelt als auch deren Nutzen anhand von  Problemstellungen aus vielen Bereichen (Medizin, industrielle Bildverarbeitung,  Objekterkennung) erlaeutert. Das Buch eignet sich sowohl fuer Studierende  der Informatik, Mathematik und Ingenieurwissenschaften als auch fuer  Anwender aus der industriellen Bildverarbeitung.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Sickert14_SVS.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Sickert14_SVS.pdf">Semantic Volume Segmentation with Iterative Context Integration</a>.</span>
            <br />
            <span class=bibauthor>Sven Sickert and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Open German-Russian Workshop on Pattern Recognition and Image Understanding  (OGRW).</span>
            
            <span class=bibpages>220-225.</span>
            
            <span class=bibyear>2014.</span>
            
            
            
            
            <a href="/bib/Sickert14_SVS"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Sickert14_SVS.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://nbn-resolving.de/urn:nbn:de:hbz:kob7-2015051206"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Sickert14_SVS');">more ...</span>
            <div class="bibabstract" id="Sickert14_SVS">
              <br />
              <div class='vspace'></div>
              Abstract: Automatic recognition of biological structures like membranes or synapses  is important to analyze organic processes and to understand their  functional behavior. To achieve this, volumetric images taken by  electron microscopy or computed tomography have to be segmented into  meaningful regions. We are extending iterative context forests which  were developed for 2D image data for image stack segmentation. In  particular, our method s able to learn high order dependencies and  import contextual information, which often can not be learned by  conventional Markov random field approaches usually used for this  task. Our method is tested for very different and challenging medical  and biological segmentation tasks.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Simon14_PDD.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Simon14_PDD.pdf">Part Detector Discovery in Deep Convolutional Neural Networks</a>.</span>
            <br />
            <span class=bibauthor>Marcel Simon and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Asian Conference on Computer Vision (ACCV).</span>
            
            <span class=bibpages>162-177.</span>
            
            <span class=bibyear>2014.</span>
            
            
            
            
            <a href="/bib/Simon14_PDD"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Simon14_PDD.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            <a href="https://github.com/cvjena/PartDetectorDisovery"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Simon14_PDD');">more ...</span>
            <div class="bibabstract" id="Simon14_PDD">
              <br />
              <div class='vspace'></div>
              Abstract: Current fine-grained classification approaches often rely  on a robust localization of object parts to extract  localized feature representations suitable for discrimination.  However, part localization is a  challenging task due to the large variation of appearance and pose.  In this paper, we show how pre-trained convolutional neural networks  can be used for robust and efficient object part discovery and localization without the  necessity to actually train the network on the current dataset. Our approach called  part detector discovery  (PDD)  is based on analyzing the gradient maps of the network outputs and finding  activation centers spatially related to annotated semantic parts or bounding boxes.  This allows us not just to obtain excellent performance on the CUB200-2011 dataset,  but in contrast to previous approaches also to perform detection and bird classification jointly  without requiring a given bounding box annotation during testing and ground-truth parts during training.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Simon14_PLE.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Simon14_PLE.pdf">Part Localization by Exploiting Deep Convolutional Networks</a>.</span>
            <br />
            <span class=bibauthor>Marcel Simon and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>ECCV Workshop on Parts and Attributes (ECCV-WS).</span>
            
            <span class=bibyear>2014.</span>
            
            
            
            
            <a href="/bib/Simon14_PLE"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Simon14_PLE.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="https://filebox.ece.vt.edu/~parikh/PnA2014/"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Goering14_NPT.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Goering14_NPT.pdf">Nonparametric Part Transfer for Fine-grained Recognition</a>.</span>
            <br />
            <span class=bibauthor>Christoph Göring and Erik Rodner and Alexander Freytag and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</span>
            
            <span class=bibpages>2489-2496.</span>
            
            <span class=bibyear>2014.</span>
            
            
            
            
            <a href="/bib/Goering14_NPT"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Goering14_NPT.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Goring_Nonparametric_Part_Transfer_2014_CVPR_paper.pdf"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            <a href="https://github.com/cvjena/finegrained-cvpr2014"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Goering14_NPT.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            


            
            <span class="abstractlink" onClick="abstractclick('Goering14_NPT');">more ...</span>
            <div class="bibabstract" id="Goering14_NPT">
              <br />
              <div class='vspace'></div>
              Abstract: In the following paper, we present an approach for fine-grained recognition based on a new part detection method.  In particular, we propose a nonparametric label transfer technique which transfers part constellations from objects with similar global shapes.  The possibility for transferring part annotations to unseen images allows for coping with a high degree of pose and view variations in scenarios where  traditional detection models (such as deformable part models) fail.  Our approach is especially  valuable for fine-grained recognition scenarios where intraclass variations are extremely high, and  precisely localized features need to be extracted.  Furthermore, we show the importance of carefully designed visual extraction strategies, such as combination of complementary feature types and  iterative image segmentation, and the resulting impact on the recognition performance.  In experiments, our simple yet powerful approach achieves 35.9% and 57.8% accuracy on the CUB-2010 and 2011 bird datasets,  which is the current best performance for these benchmarks.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2013</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Bodesheim13_AEA.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Bodesheim13_AEA.pdf">An Efficient Approximation for Gaussian Process Regression</a>.</span>
            <br />
            <span class=bibauthor>Paul Bodesheim and Alexander Freytag and Erik Rodner and Joachim Denzler.</span>
            <br />
            
            
            
            <span class=bibyear>2013.</span>
            
            
            
            <span class=note> Technical Report TR-FSU-INF-CV-2013-01</span>
            
            
            <a href="/bib/Bodesheim13_AEA"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Bodesheim13_AEA.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Bodesheim13_AOG.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Bodesheim13_AOG.pdf">Approximations of Gaussian Process Uncertainties for Visual Recognition  Problems</a>.</span>
            <br />
            <span class=bibauthor>Paul Bodesheim and Alexander Freytag and Erik Rodner and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>Scandinavian Conference on Image Analysis (SCIA).</span>
            
            <span class=bibpages>182-194.</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Bodesheim13_AOG"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Bodesheim13_AOG.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Bodesheim13_KNS.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Bodesheim13_KNS.pdf">Kernel Null Space Methods for Novelty Detection</a>.</span>
            <br />
            <span class=bibauthor>Paul Bodesheim and Alexander Freytag and Erik Rodner and Michael  Kemmler and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</span>
            
            <span class=bibpages>3374-3381.</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Bodesheim13_KNS"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Bodesheim13_KNS.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://www.inf-cv.uni-jena.de/novelty_detection.html"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            <a href="https://github.com/cvjena/knfst"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Bodesheim13_KNS.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Denzler13_BTC.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Denzler13_BTC.pdf">Beyond the closed-world assumption: The importance of novelty detection  and open set recognition</a>.</span>
            <br />
            <span class=bibauthor>Joachim Denzler and Erik Rodner and Paul Bodesheim and Alexander  Freytag.</span>
            <br />
            <span class=bibvenue>GCPR Workshop on Unsolved Problems in Pattern Recognition (GCPR-WS).</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Denzler13_BTC"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Denzler13_BTC.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Donahue13_SSD.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Donahue13_SSD.pdf">Semi-Supervised Domain Adaptation with Instance Constraints</a>.</span>
            <br />
            <span class=bibauthor>Jeff Donahue and Judy Hoffman and Erik Rodner and Kate Saenko and  Trevor Darrell.</span>
            <br />
            <span class=bibvenue>IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</span>
            
            <span class=bibpages>668 - 675.</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Donahue13_SSD"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Donahue13_SSD.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Froehlich13_GSS.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Froehlich13_GSS.pdf">Large-Scale Gaussian Process Multi-Class Classification for Semantic  Segmentation and Facade Recognition</a>.</span>
            <br />
            <span class=bibauthor>Björn Fröhlich and Erik Rodner and Michael Kemmler and Joachim  Denzler.</span>
            <br />
            
            <span class=bibvenue>Machine Vision and Applications.</span>
            
            
            <span class=bibpages>24(5):</span>
            
            
            <span class=bibpages>1043-1053.</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Froehlich13_GSS"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Froehlich13_GSS.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Freytag13_LET.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Freytag13_LET.pdf">Labeling examples that matter: Relevance-Based Active Learning with  Gaussian Processes</a>.</span>
            <br />
            <span class=bibauthor>Alexander Freytag and Erik Rodner and Paul Bodesheim and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>German Conference on Pattern Recognition (GCPR).</span>
            
            <span class=bibpages>282-291.</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Freytag13_LET"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Freytag13_LET.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            <a href="https://github.com/cvjena/activeLearning-GP"><img src="img/code-link.png" alt="code" title="code"
                target="_blank" /></a>
            
            
            
            <a href="file:///Users/rodner/dev/webpage//supplementary/Freytag13_LET.supplementary.pdf"><img src="supplementary.png"
                alt="supplementary" title="supplementary" target="_blank" /></a>
            


            
            <span class="abstractlink" onClick="abstractclick('Freytag13_LET');">more ...</span>
            <div class="bibabstract" id="Freytag13_LET">
              <br />
              <div class='vspace'></div>
              Abstract: Active learning is an essential tool to reduce manual annotation costs  in the presence of large amounts of unsupervised data. In this paper,  we introduce new active learning methods based on measuring the impact  of a new example on the current model. This is done by deriving model  changes of Gaussian process models in closed form.  Furthermore, we study typical pitfalls in active learning and show  that our methods automatically balance between the exploitation and  the exploration trade-off. Experiments are performed with established  benchmark datasets for visual object recognition and show that our  new active learning techniques are able to outperform state-of-the-art  methods.  <p> <a href="http://www.inf-cv.uni-jena.de">Supplementary Material</a>  </p>
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Goering13_FGC.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Goering13_FGC.pdf">Fine-grained Categorization - Short Summary of our Entry for the  ImageNet Challenge 2012</a>.</span>
            <br />
            <span class=bibauthor>Christoph Göring and Alexander Freytag and Erik Rodner and Joachim  Denzler.</span>
            <br />
            
            <span class=bibvenue>arXiv preprint arXiv:1310.4759.</span>
            
            
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Goering13_FGC"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Goering13_FGC.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://arxiv.org/abs/1310.4759"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Hoffman13_ELD.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Hoffman13_ELD.pdf">Efficient Learning of Domain-invariant Image Representations</a>.</span>
            <br />
            <span class=bibauthor>Judy Hoffman and Erik Rodner and Jeff Donahue and Trevor Darrell  and Kate Saenko.</span>
            <br />
            <span class=bibvenue>International Conference on Learning Representations (ICLR).</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Hoffman13_ELD"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Hoffman13_ELD.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kemmler13_SMC.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kemmler13_SMC.pdf">Segmentation of Microorganism in Complex Environments</a>.</span>
            <br />
            <span class=bibauthor>Michael Kemmler and Björn Fröhlich and Erik Rodner and Joachim  Denzler.</span>
            <br />
            
            <span class=bibvenue>Pattern Recognition and Image Analysis. Advances in Mathematical  Theory and Applications (PRIA).</span>
            
            
            <span class=bibpages>23(4):</span>
            
            
            <span class=bibpages>512-517.</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Kemmler13_SMC"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kemmler13_SMC.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kemmler13_AIN.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kemmler13_AIN.pdf">Automatic Identification of Novel Bacteria using Raman Spectroscopy  and Gaussian Processes</a>.</span>
            <br />
            <span class=bibauthor>Michael Kemmler and Erik Rodner and Petra Rösch and Jürgen Popp  and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>Analytica Chimica Acta.</span>
            
            
            
            <span class=bibpages>29-37.</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Kemmler13_AIN"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kemmler13_AIN.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://www.ncbi.nlm.nih.gov/pubmed/23972972"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            
            <a href="file:///Users/rodner/dev/webpage//supplementary/Kemmler13_AIN.supplementary.pdf"><img src="supplementary.png"
                alt="supplementary" title="supplementary" target="_blank" /></a>
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kemmler13_OCG.pdf">One-class Classification with Gaussian Processes</a>.</span>
            <br />
            <span class=bibauthor>Michael Kemmler and Erik Rodner and Esther-Sabrina Wacker and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>Pattern Recognition.</span>
            
            
            
            <span class=bibpages>3507-3518.</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Kemmler13_OCG"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kemmler13_OCG.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Luetz13_IWT.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Luetz13_IWT.pdf">I Want To Know More: Efficient Multi-Class Incremental Learning Using  Gaussian Processes</a>.</span>
            <br />
            <span class=bibauthor>Alexander Lütz and Erik Rodner and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>Pattern Recognition and Image Analysis. Advances in Mathematical  Theory and Applications (PRIA).</span>
            
            
            <span class=bibpages>23(3):</span>
            
            
            <span class=bibpages>402-407.</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Luetz13_IWT"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Luetz13_IWT.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner13_STDa.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner13_STDa.pdf">Scalable Transform-based Domain Adaptation</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Judy Hoffman and Jeff Donahue and Trevor Darrell  and Kate Saenko.</span>
            <br />
            <span class=bibvenue>ICCV Workshop on Visual Domain Adaptation (ICCV-WS).</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Rodner13_STDa"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner13_STDa.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner13_TAI.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner13_TAI.pdf">Towards Adapting ImageNet to Reality: Scalable Domain Adaptation  with Implicit Low-rank Transformations</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Judy Hoffman and Jeff Donahue and Trevor Darrell  and Kate Saenko.</span>
            <br />
            
            <span class=bibvenue>arXiv preprint arXiv:1308.4200.</span>
            
            
            
            <span class=bibyear>2013.</span>
            
            
            
            
            <a href="/bib/Rodner13_TAI"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner13_TAI.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner13_TBD.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner13_TBD.pdf">Transform-based Domain Adaptation for Big Data</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Judy Hoffman and Jeff Donahue and Trevor Darrell and Kate Saenko.</span>
            <br />
            <span class=bibvenue>NIPS Workshop on New Directions in Transfer and Multi-Task Learning (NIPS-WS).</span>
            
            <span class=bibyear>2013.</span>
            
            
            
            <span class=note> abstract version of arXiv:1308.4200</span>
            
            
            <a href="/bib/Rodner13_TBD"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner13_TBD.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Rodner13_TBD');">more ...</span>
            <div class="bibabstract" id="Rodner13_TBD">
              <br />
              <div class='vspace'></div>
              Abstract: Images seen during test time are often not from the same distribution  as images used for learning. This problem, known as domain shift,  occurs when training classifiers from object-centric internet image  databases and trying to apply them directly to scene understanding  tasks. The consequence is often severe performance degradation and  is one of the major barriers for the application of classi- fiers  in real-world systems. In this paper, we show how to learn transform-based  domain adaptation classifiers in a scalable manner. The key idea  is to exploit an implicit rank constraint, originated from a max-margin  domain adaptation formulation, to make optimization tractable. Experiments  show that the transformation between domains can be very efficiently  learned from data and easily applied to new categories
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2012</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Bodesheim12_DOC.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Bodesheim12_DOC.pdf">Divergence-Based One-Class Classification Using Gaussian Processes</a>.</span>
            <br />
            <span class=bibauthor>Paul Bodesheim and Erik Rodner and Alexander Freytag and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>British Machine Vision Conference (BMVC).</span>
            
            <span class=bibpages>50.1-50.11.</span>
            
            <span class=bibyear>2012.</span>
            
            
            
            <span class=note> http://dx.doi.org/10.5244/C.26.50</span>
            
            
            <a href="/bib/Bodesheim12_DOC"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Bodesheim12_DOC.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Bodesheim12_DOC.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Froehlich12_ATG.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Froehlich12_ATG.pdf">As Time Goes By: Anytime Semantic Segmentation with Iterative Context  Forests</a>.</span>
            <br />
            <span class=bibauthor>Björn Fröhlich and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Symposium of the German Association for Pattern Recognition (DAGM).</span>
            
            <span class=bibpages>1-10.</span>
            
            <span class=bibyear>2012.</span>
            
            
            
            
            <a href="/bib/Froehlich12_ATG"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Froehlich12_ATG.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Froehlich12_SSM.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Froehlich12_SSM.pdf">Semantic Segmentation with Millions of Features: Integrating Multiple  Cues in a Combined Random Forest Approach</a>.</span>
            <br />
            <span class=bibauthor>Björn Fröhlich and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Asian Conference on Computer Vision (ACCV).</span>
            
            <span class=bibpages>218-231.</span>
            
            <span class=bibyear>2012.</span>
            
            
            
            
            <a href="/bib/Froehlich12_SSM"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Froehlich12_SSM.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Froehlich12_LGP.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Froehlich12_LGP.pdf">Large-Scale Gaussian Process Classification using Random Decision  Forests</a>.</span>
            <br />
            <span class=bibauthor>Björn Fröhlich and Erik Rodner and Michael Kemmler and Joachim  Denzler.</span>
            <br />
            
            <span class=bibvenue>Pattern Recognition and Image Analysis. Advances in Mathematical  Theory and Applications (PRIA).</span>
            
            
            <span class=bibpages>22(1):</span>
            
            
            <span class=bibpages>113-120.</span>
            
            <span class=bibyear>2012.</span>
            
            
            
            
            <a href="/bib/Froehlich12_LGP"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Froehlich12_LGP.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Freytag12_ESS.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Freytag12_ESS.pdf">Efficient Semantic Segmentation with Gaussian Processes and Histogram  Intersection Kernels</a>.</span>
            <br />
            <span class=bibauthor>Alexander Freytag and Björn Fröhlich and Erik Rodner and  Joachim Denzler.</span>
            <br />
            <span class=bibvenue>International Conference on Pattern Recognition (ICPR).</span>
            
            <span class=bibpages>3313-3316.</span>
            
            <span class=bibyear>2012.</span>
            
            
            
            
            <a href="/bib/Freytag12_ESS"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Freytag12_ESS.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Freytag12_BCL.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Freytag12_BCL.pdf">Beyond Classification - Large-scale Gaussian Process Inference and  Uncertainty Prediction</a>.</span>
            <br />
            <span class=bibauthor>Alexander Freytag and Erik Rodner and Paul Bodesheim and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>Big Data Meets Computer Vision: First International Workshop on Large  Scale Visual Recognition and Retrieval (NIPS-WS).</span>
            
            <span class=bibyear>2012.</span>
            
            
            
            <span class=note> This workshop article is a short version abstract of our ACCV'12  paper.</span>
            
            
            <a href="/bib/Freytag12_BCL"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Freytag12_BCL.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Freytag12_RUC.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Freytag12_RUC.pdf">Rapid Uncertainty Computation with Gaussian Processes and Histogram  Intersection Kernels</a>.</span>
            <br />
            <span class=bibauthor>Alexander Freytag and Erik Rodner and Paul Bodesheim and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>Asian Conference on Computer Vision (ACCV).</span>
            
            <span class=bibpages>511-524.</span>
            
            <span class=bibyear>2012.</span>
            
            
            <span class=awardnote> Best Paper Honorable Mention Award</span>
            
            <a href="/bib/Freytag12_RUC"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Freytag12_RUC.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Freytag12_RUC.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Jiang12_MTB.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Jiang12_MTB.pdf">Multi-Person Tracking-by-Detection based on Calibrated Multi-Camera  Systems</a>.</span>
            <br />
            <span class=bibauthor>Xiaoyan Jiang and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>International Conference on Computer Vision and Graphics.</span>
            
            <span class=bibpages>743-751.</span>
            
            <span class=bibyear>2012.</span>
            
            
            
            
            <a href="/bib/Jiang12_MTB"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Jiang12_MTB.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner12_LWB.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner12_LWB.pdf">Lernen mit wenigen Beispielen für die visuelle Objekterkennung</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner.</span>
            <br />
            <span class=bibvenue>Ausgezeichnete Informatikdissertationen 2011.</span>
            
            <span class=bibyear>2012.</span>
            
            
            
            <span class=note> in german</span>
            
            
            <a href="/bib/Rodner12_LWB"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner12_LWB.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://www.gi.de/service/publikationen/lni/mehr-zur-schriftenreihe/dissertations/gi-edition-lecture-notes-in-informatics-lni-d-12.html"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner12_LGP.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner12_LGP.pdf">Large-Scale Gaussian Process Classification with Flexible Adaptive  Histogram Kernels</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Alexander Freytag and Paul Bodesheim and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>European Conference on Computer Vision (ECCV).</span>
            
            <span class=bibpages>85-98.</span>
            
            <span class=bibyear>2012.</span>
            
            
            
            
            <a href="/bib/Rodner12_LGP"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner12_LGP.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            
            <a href="file:///Users/rodner/dev/webpage//supplementary/Rodner12_LGP.supplementary.pdf"><img src="supplementary.png"
                alt="supplementary" title="supplementary" target="_blank" /></a>
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2011</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Froehlich11_EGp.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Froehlich11_EGp.pdf">Efficient Gaussian process classification using random decision forests</a>.</span>
            <br />
            <span class=bibauthor>Björn Fröhlich and Erik Rodner and Michael Kemmler and Joachim  Denzler.</span>
            <br />
            
            <span class=bibvenue>Pattern Recognition and Image Analysis. Advances in Mathematical  Theory and Applications (PRIA).</span>
            
            
            
            <span class=bibpages>184-187.</span>
            
            <span class=bibyear>2011.</span>
            
            
            
            <span class=note> 10.1134/S1054661811020337</span>
            
            
            <a href="/bib/Froehlich11_EGp"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Froehlich11_EGp.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kemmler11_DOM.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kemmler11_DOM.pdf">Detection of Microorganisms in Complex Microscopy Images</a>.</span>
            <br />
            <span class=bibauthor>Michael Kemmler and Björn Fröhlich and Erik Rodner and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>Open German-Russian Workshop on Pattern Recognition  and Image Understanding (OGRW).</span>
            
            <span class=bibpages>115-118.</span>
            
            <span class=bibyear>2011.</span>
            
            
            
            
            <a href="/bib/Kemmler11_DOM"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kemmler11_DOM.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Luetz11_EIL.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Luetz11_EIL.pdf">Efficient Multi-Class Incremental Learning Using Gaussian Processes</a>.</span>
            <br />
            <span class=bibauthor>Alexander Lütz and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Open German-Russian Workshop on Pattern Recognition and Image Understanding  (OGRW).</span>
            
            <span class=bibpages>182-185.</span>
            
            <span class=bibyear>2011.</span>
            
            
            
            
            <a href="/bib/Luetz11_EIL"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Luetz11_EIL.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Luetz11_EIL');">more ...</span>
            <div class="bibabstract" id="Luetz11_EIL">
              <br />
              <div class='vspace'></div>
              Abstract: One of the main assumptions in machine learning is that sufficient  training data is available in advance and batch learning can be applied.  However, because of the dynamics in a lot of applications, this assumption  will break down in almost all cases over time. Therefore, classifiers  have to be able to adapt themselves when new training data from existing  or new classes becomes available, training data is changed or should  be even removed. In this paper, we present a method allowing efficient  incremental learning of a Gaussian process classifier. Experimental  results show the benefits in terms of needed computation times compared  to building the classifier from the scratch.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner11_Diss.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner11_Diss.pdf">Learning from Few Examples for Visual Recognition Problems</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner.</span>
            <br />
            
            
            
            <span class=bibyear>2011.</span>
            
            
            
            
            <a href="/bib/Rodner11_Diss"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner11_Diss.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://www.dr.hut-verlag.de/978-3-8439-0249-6.html"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner11_LFE.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner11_LFE.pdf">Learning with Few Examples for Binary and Multiclass Classification  Using Regularization of Randomized Trees</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>Pattern Recognition Letters.</span>
            
            
            <span class=bibpages>32(2):</span>
            
            
            <span class=bibpages>244-251.</span>
            
            <span class=bibyear>2011.</span>
            
            
            
            
            <a href="/bib/Rodner11_LFE"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner11_LFE.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner11_OCA.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner11_OCA.pdf">One-Class Classification for Anomaly Detection in Wire Ropes with  Gaussian Processes in a Few Lines of Code</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Esther-Sabrina Wacker and Michael Kemmler and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>Machine Vision Applications (MVA).</span>
            
            <span class=bibpages>219-222.</span>
            
            <span class=bibyear>2011.</span>
            
            
            
            
            <a href="/bib/Rodner11_OCA"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner11_OCA.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2010</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Froehlich10_AFA.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Froehlich10_AFA.pdf">A Fast Approach for Pixelwise Labeling of Facade Images</a>.</span>
            <br />
            <span class=bibauthor>Björn Fröhlich and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>International Conference on Pattern Recognition  (ICPR).</span>
            
            <span class=bibpages>3029-3032.</span>
            
            <span class=bibyear>2010.</span>
            
            
            
            
            <a href="/bib/Froehlich10_AFA"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Froehlich10_AFA.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Froehlich10_EGP.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Froehlich10_EGP.pdf">Efficient Gaussian Process Classification using Random Decision Forests</a>.</span>
            <br />
            <span class=bibauthor>Björn Fröhlich and Erik Rodner and Michael Kemmler and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>International Conference on Pattern Recognition  and Image Analysis (PRIA),  St. Petersburg, Russia.</span>
            
            <span class=bibpages>93-96.</span>
            
            <span class=bibyear>2010.</span>
            
            
            
            
            <a href="/bib/Froehlich10_EGP"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Froehlich10_EGP.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kemmler10_OCC.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kemmler10_OCC.pdf">One-Class Classification with Gaussian Processes</a>.</span>
            <br />
            <span class=bibauthor>Michael Kemmler and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Asian Conference on Computer Vision (ACCV).</span>
            
            <span class=bibpages>489-500.</span>
            
            <span class=bibyear>2010.</span>
            
            
            
            
            <a href="/bib/Kemmler10_OCC"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kemmler10_OCC.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Kemmler10_OCC.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner10_OSL.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner10_OSL.pdf">One-Shot Learning of Object Categories using Dependent Gaussian Processes</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Annual Symposium of the German Association  for Pattern Recognition (DAGM).</span>
            
            <span class=bibpages>232-241.</span>
            
            <span class=bibyear>2010.</span>
            
            
            
            
            <a href="/bib/Rodner10_OSL"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner10_OSL.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner10_MKG.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner10_MKG.pdf">Multiple Kernel Gaussian Process Classification for Generic 3D Object  Recognition From Time-of-Flight Images</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Doaa Hegazy and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>International Conference on Image and Vision Computing.</span>
            
            <span class=bibpages>1-8.</span>
            
            <span class=bibyear>2010.</span>
            
            
            
            
            <a href="/bib/Rodner10_MKG"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner10_MKG.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            <a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6148815"><img src="img/web-link.png" alt="www" title="www"
                target="_blank" /></a>
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2009</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kemmler09_GCE.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kemmler09_GCE.pdf">Global Context Extraction for Object Recognition Using a Combination  of Range and Visual Features</a>.</span>
            <br />
            <span class=bibauthor>Michael Kemmler and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Dynamic 3D Imaging Workshop.</span>
            
            <span class=bibpages>96-109.</span>
            
            <span class=bibyear>2009.</span>
            
            
            
            
            <a href="/bib/Kemmler09_GCE"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kemmler09_GCE.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner09_RPL.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner09_RPL.pdf">Randomized Probabilistic Latent Semantic Analysis for Scene Recognition</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Iberoamerican Congress on Pattern Recognition  (CIARP).</span>
            
            <span class=bibpages>945-953.</span>
            
            <span class=bibyear>2009.</span>
            
            
            
            
            <a href="/bib/Rodner09_RPL"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner09_RPL.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner09_LFE.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner09_LFE.pdf">Learning with Few Examples by Transferring Feature Relevance</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Annual Symposium of the German Association  for Pattern Recognition (DAGM).</span>
            
            <span class=bibpages>252-261.</span>
            
            <span class=bibyear>2009.</span>
            
            
            
            
            <a href="/bib/Rodner09_LFE"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner09_LFE.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2008</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Kaehler08_OFO.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Kaehler08_OFO.pdf">On Fusion of Range and Intensity Information Using Graph-Cut for  Planar Patch Segmentation</a>.</span>
            <br />
            <span class=bibauthor>Olaf Kähler and Erik Rodner and Joachim Denzler.</span>
            <br />
            
            <span class=bibvenue>International Journal of Intelligent Systems Technologies and Applications.</span>
            
            
            <span class=bibpages>5(3/4):</span>
            
            
            <span class=bibpages>365-373.</span>
            
            <span class=bibyear>2008.</span>
            
            
            
            
            <a href="/bib/Kaehler08_OFO"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Kaehler08_OFO.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Kaehler08_OFO');">more ...</span>
            <div class="bibabstract" id="Kaehler08_OFO">
              <br />
              <div class='vspace'></div>
              Abstract: Planar patch detection aims at simplifying data from 3-D imaging sensors  to a more compact scene description. We propose a fusion of intensity  and depth information using Graph-Cut methods for this problem. Different  known algorithms are additionally evaluated on lowresolution high-framerate  image sequences and used as an initialization for the Graph-Cut approach.  In experiments we show a significant improvement of the detected  patch boundaries after the refinement with our method.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner08_LFE.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner08_LFE.pdf">Learning with Few Examples using a Constrained Gaussian Prior on  Randomized Trees</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Vision, Modelling, and Visualization Workshop (VMV).</span>
            
            <span class=bibpages>159-168.</span>
            
            <span class=bibyear>2008.</span>
            
            
            
            
            <a href="/bib/Rodner08_LFE"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner08_LFE.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            


            
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
            
            <img width=90% class=teaserimg src="file:///Users/rodner/dev/webpage//teaser/Rodner08_DBF.teaser.png">
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              <a
                href="file:///Users/rodner/dev/webpage//pdf/Rodner08_DBF.pdf">Difference of Boxes Filters Revisited: Shadow Suppression and Efficient  Character Segmentation</a>.</span>
            <br />
            <span class=bibauthor>Erik Rodner and Herbert Süße and Wolfgang Ortmann and Joachim  Denzler.</span>
            <br />
            <span class=bibvenue>IAPR Workshop on Document Analysis Systems.</span>
            
            <span class=bibpages>263-269.</span>
            
            <span class=bibyear>2008.</span>
            
            
            
            
            <a href="/bib/Rodner08_DBF"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            <a href="file:///Users/rodner/dev/webpage//pdf/Rodner08_DBF.pdf"><img src="img/pdf-document.png" alt="pdf"
                title="pdf" /></a>
            
            
            
            
            <a href="file:///Users/rodner/dev/webpage//presentation/Rodner08_DBF.presentation.pdf"><img src="img/presentation.png"
                alt="presentation" title="presentation" target="_blank" /></a>
            
            


            
            <span class="abstractlink" onClick="abstractclick('Rodner08_DBF');">more ...</span>
            <div class="bibabstract" id="Rodner08_DBF">
              <br />
              <div class='vspace'></div>
              Abstract: A robust segmentation is the most important part of an automatic character  recognition system (e.g. document pro- cessing, license plate recognition  etc.). In our contribution we present an efficient segmentation framework  using a pre- processing step for shadow suppression combined with  a local thresholding technique. The method is based on a combination  of difference of boxes filters and a new ternary segmentation, which  are both simple low-level image oper- ations. We also draw parallels  to a recently published work on a ganglion cell model and show that  our approach is theoret- ically more substantiated as well as more  robust and more efficient in practice. Systematic evaluation of noisy  input data as well as results on a large dataset of license plate  images 1 show the robustness and efficiency of our proposed method.  Our results can be applied easily to any optical char- acter recognition  system resulting in an impressive gain of robustness against nonlinear  illumination.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
    <h2>2007</h2>
    
    <div class='paperblock'>
      
        <table width=100%>
          
          
          <td width=150px>
            
            
          </td>

          <td style='vertical-align:middle'>
            
            <span class=bibtitle>
              On Fusion of Range and Intensity Information Using Graph-Cut for  Planar Patch Segmentation.</span>
            <br />
            <span class=bibauthor>Olaf Kähler and Erik Rodner and Joachim Denzler.</span>
            <br />
            <span class=bibvenue>Proceedings Dynamic 3D Imaging Workshop.</span>
            
            <span class=bibpages>113-121.</span>
            
            <span class=bibyear>2007.</span>
            
            
            
            <span class=note> also appeared in International Journal of Intelligent Systems Technologies  and Applications, Vol. 5, No. 3/4, pp.365-373</span>
            
            
            <a href="/bib/Kaehler07_OFO"
              onlick="window.open(this.href,'bibtex','toolbar=no,menubar=no,status=no,height=400,width=600,resizable=yes'); return false;"><img
                src="img/get-bib-source.png" alt="BibTeX" /></a>
            
            
            
            
            


            
            <span class="abstractlink" onClick="abstractclick('Kaehler07_OFO');">more ...</span>
            <div class="bibabstract" id="Kaehler07_OFO">
              <br />
              <div class='vspace'></div>
              Abstract: Planar patch detection aims at simplifying data from 3-D imaging sensors  to a more compact scene description. We propose a fusion of intensity  and depth information using Graph-Cut methods for this problem. Different  known algorithms are additionally evaluated on lowresolution high-framerate  image sequences and used as an initialization for the Graph-Cut approach.  In experiments we show a significant improvement of the detected  patch boundaries after the refinement with our method.
              
            </div>
          </td>
        </table>

    </div>
    <div class='vspace'></div>
    
    
  </div>

</body>

</html>